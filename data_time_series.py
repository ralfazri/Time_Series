# -*- coding: utf-8 -*-
"""Data Time Series

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZPl09DfUUjiDNQLoFxb3CXpcSCCiiJXr
"""

#download dataset from kaggle dataset
from google.colab import files
files.upload()
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json
!ls ~/.kaggle
!kaggle datasets download -d mahirkukreja/delhi-weather-data

#install kaggle package
!pip install -q kaggle

#unzip file
!mkdir delhi-weather-data
!unzip testset.csv.zip -d delhi-weather-data
!ls delhi-weather-data

import pandas as pd
df_weather_tsm = pd.read_csv('delhi-weather-data/testset.csv')
df_weather_tsm.head()

"""Remove 'Underscore' from columns (Modify Columns)"""

df_weather_tsm.columns = [column.strip().replace('_','') for column in df_weather_tsm]

df_weather_tsm.head()

"""Show Min Max Data"""

df_weather_tsm.min()

df_weather_tsm.max()

"""Show List Columns"""

df_weather_tsm.columns

"""Shape of Data Weather"""

print('Total Row : ', df_weather_tsm.shape[0])
print('Total Columns : ', df_weather_tsm.shape[1])
df_weather_tsm.shape

"""Data Visualization"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

plt.style.use('seaborn')

sns.displot(df_weather_tsm['tempm'], bins=50)
plt.show()

data_weather = df_weather_tsm[['datetimeutc','tempm']].copy()
data_weather['datetimeutc'] = pd.to_datetime(data_weather['datetimeutc'])
data_weather.set_index('datetimeutc', inplace = True)
data_weather.head()

plt.figure(figsize=(20,8))
plt.plot(data_weather)
plt.title("Weather Data")
plt.xlabel('datetimeutc')
plt.ylabel('Scale')
plt.show()

"""Data Processing,
Modify columns to only using columns ('datetimeutc','tempm')
"""

df_weather_tsm = df_weather_tsm[['datetimeutc','tempm']]

df_weather_tsm.head()

"""Change datetimeutc format string to dateTime type"""

df_weather_tsm['datetimeutc'] = pd.to_datetime(df_weather_tsm['datetimeutc']).dt.strftime('%Y-%m-%d %H:%M')
df_weather_tsm.sort_values('datetimeutc', inplace=True, ignore_index=True)
df_weather_tsm.head()

"""Handling Missing Value"""

df_weather_tsm.isnull().any()

df_weather_tsm.isna().any()

df_weather_tsm['tempm'].fillna(df_weather_tsm['tempm'].mean(), inplace=True)

"""Show Outlier"""

sns.boxplot(x=df_weather_tsm['tempm'])

"""Remove Outlier"""

Q1 = df_weather_tsm.quantile(0.25)
Q3 = df_weather_tsm.quantile(0.75)
print(Q1)
print(Q3)

IQR = Q3 - Q1
print(IQR)

outlier = (df_weather_tsm < (Q1-1.5*IQR)) | (df_weather_tsm > (Q3-1.5*IQR))
pd.set_option('display.max_rows', outlier.shape[0]+1)
outlier[outlier['tempm'] == True]

df_weather_tsm_out = df_weather_tsm[~((df_weather_tsm < (Q1-1.5*IQR)) | (df_weather_tsm > (Q3-1.5*IQR))).any(axis=1)]
df_weather_tsm_out.shape

"""Normalization Data"""

from sklearn.preprocessing import MinMaxScaler
mx = MinMaxScaler()

df_weather_tsm['tempm'] = mx.fit_transform(df_weather_tsm[['tempm']])
df_weather_tsm.head()

"""Split Data"""

datetimne = df_weather_tsm['datetimeutc'].values
temp = df_weather_tsm['tempm'].values

datetimne

temp

"""Setting Data, 80% to Training set and 20% to Validation set"""

from sklearn.model_selection import train_test_split

x_train, x_test, y_train, y_test = train_test_split(datetimne, temp, test_size = 0.2, random_state = 0, shuffle = False)

print(len(x_train), len(x_test))

"""Windowed"""

import tensorflow as tf

def windowed_dataset(series, window_size, batch_size, shuffle_buffer):
  series = tf.expand_dims(series, axis=1)
  ds = tf.data.Dataset.from_tensor_slices(series)
  ds = ds.window(window_size + 1, shift = 1, drop_remainder = True)
  ds = ds.flat_map(lambda w: w.batch(window_size + 1))
  ds = ds.shuffle(shuffle_buffer)
  ds = ds.map(lambda w: (w[: 1], w[-1:]))
  return ds.batch(batch_size).prefetch(1)

data_x_train = windowed_dataset(y_train, window_size=60, batch_size=100, shuffle_buffer=5000)
data_x_test = windowed_dataset(y_test, window_size=60, batch_size=100, shuffle_buffer=5000)

"""Data Modelling"""

from keras.layers import Dense, LSTM
model = tf.keras.models.Sequential([
    tf.keras.layers.Conv1D(32, 5, padding='causal',activation='relu', input_shape=[None, 1]),
    tf.keras.layers.LSTM(64, return_sequences=True),
    tf.keras.layers.LSTM(64),
    tf.keras.layers.Dense(30, activation="relu"),
    tf.keras.layers.Dense(10, activation="relu"),
    tf.keras.layers.Dense(1),
])

"""Callback"""

max = df_weather_tsm['tempm'].max()
min = df_weather_tsm['tempm'].min()

x = (max - min) * 0.1
print(x)

class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('mae') < x and logs.get('val_mae') < x):
      self.model.stop_training = True
      print('Mae model < 10% of data')
callbacks = myCallback()

"""Train Model"""

optimizer = tf.keras.optimizers.SGD(learning_rate=1.0000e-04, momentum=0.9)
model.compile(loss=tf.keras.losses.Huber(),
              optimizer=optimizer,
              metrics=['mae'])

history = model.fit(
    data_x_train,
    epochs = 50,
    validation_data=(data_x_test),
    verbose=2,
    callbacks=[callbacks]
)

"""Visualization Loss and MAE"""

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train','test'], loc='upper right')
plt.show()

plt.plot(history.history['mae'])
plt.plot(history.history['val_mae'])
plt.title('MAE')
plt.ylabel('mae')
plt.xlabel('epoch')
plt.legend(['train','test'], loc='upper right')
plt.show()